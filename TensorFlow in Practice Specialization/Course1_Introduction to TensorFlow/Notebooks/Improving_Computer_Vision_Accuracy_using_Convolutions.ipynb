{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Improving Computer Vision Accuracy using Convolutions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjZoSh1xx6Xc",
        "colab_type": "text"
      },
      "source": [
        "Previously, we had a taste of how a DNN would work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFkNiSHAxgmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Oy8uAFix5Bl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5778bfd3-0f4a-4af5-eb37-57dbd5fa26e3"
      },
      "source": [
        "(train_imgs, train_labels), (test_imgs, test_labels) = mnist.load_data()\n",
        "train_imgs=train_imgs / 255.0\n",
        "test_imgs=test_imgs / 255.0\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Flatten(),\n",
        "                             tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                             tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                            ])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_imgs, train_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_imgs, test_labels)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4994 - accuracy: 0.8256\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3755 - accuracy: 0.8648\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3371 - accuracy: 0.8766\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3148 - accuracy: 0.8853\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2941 - accuracy: 0.8921\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3451 - accuracy: 0.8766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkAf22O0zttl",
        "colab_type": "text"
      },
      "source": [
        "The result was not bad at all, getting 89% on training and 87% on testing. In this lession we would like to imrpove the results further by using CNN.\n",
        "\n",
        "The objective of CNN is to narrow down the content of the image to focus on specific, distinct, details. We will see an example below:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b33X3SF2WpA",
        "colab_type": "text"
      },
      "source": [
        "Step 1 is to gather the data. You'll notice that there's a bit of a change here in that the training data needed to be reshaped. That's because the first convolution expects a single tensor containing everything, so instead of 60,000 28x28x1 items in a list, we have a single 4D list that is 60,000x28x28x1, and the same for the test images. If you don't do this, you'll get an error when training as the Convolutions do not recognize the shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5SVciRCzMSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "42aabbd1-50aa-4824-f847-f3fb1b9a269b"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBfuU5yk2e8r",
        "colab_type": "text"
      },
      "source": [
        "Next is to define your model. Now instead of the input layer at the top, you're going to add a Convolution. The parameters are:\n",
        "\n",
        "1. The number of convolutions you want to generate. Purely arbitrary, but good to start with something in the order of 32\n",
        "2. The size of the Convolution, in this case a 3x3 grid\n",
        "3. The activation function to use -- in this case we'll use relu, which you might recall is the equivalent of returning x when x>0, else returning 0\n",
        "4. In the first layer, the shape of the input data.\n",
        "\n",
        "You'll follow the Convolution with a MaxPooling layer which is then designed to compress the image, while maintaining the content of the features that were highlighted by the convlution. By specifying (2,2) for the MaxPooling, the effect is to quarter the size of the image. Without going into too much detail here, the idea is that it creates a 2x2 array of pixels, and picks the biggest one, thus turning 4 pixels into 1. It repeats this across the image, and in so doing halves the number of horizontal, and halves the number of vertical pixels, effectively reducing the image by 25%.\n",
        "\n",
        "You can call model.summary() to see the size and shape of the network, and you'll notice that after every MaxPooling layer, the image size is reduced in this way. \n",
        "\n",
        "\n",
        "```\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugy7PVIB0PBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "                                    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "                                    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(10, activation='softmax')\n",
        "                                  ])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEtUQgTc1Iic",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "32c33688-4050-454e-8783-ae5cf4b371ed"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4408 - accuracy: 0.8404\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2901 - accuracy: 0.8925\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2460 - accuracy: 0.9085\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2132 - accuracy: 0.9212\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1879 - accuracy: 0.9290\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2644 - accuracy: 0.9044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6S_8dqW0P-L",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bWRPqi62p6o",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing the Convolutions and Pooling\n",
        "\n",
        "This code will show us the convolutions graphically. The print (test_labels[;100]) shows us the first 100 labels in the test set, and you can see that the ones at index 0, index 23 and index 28 are all the same value (9). They're all shoes. Let's take a look at the result of running the convolution on each, and you'll begin to see common features between them emerge. Now, when the DNN is training on that data, it's working with a lot less, and it's perhaps finding a commonality between shoes based on this convolution/pooling combination."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FxHIBcI2qfc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ee370ec9-2b2e-41ac-d618-a6755c9d513e"
      },
      "source": [
        "print(test_labels[:100])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
            " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
            " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bzpEXOv2vK7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "a7e5bdc7-7700-4cb4-b041-51b6fdfe58ed"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f, axarr = plt.subplots(3,4)\n",
        "FIRST_IMAGE=0\n",
        "SECOND_IMAGE=7\n",
        "THIRD_IMAGE=26\n",
        "CONVOLUTION_NUMBER = 1\n",
        "from tensorflow.keras import models\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
        "for x in range(0,4):\n",
        "  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[0,x].grid(False)\n",
        "  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[1,x].grid(False)\n",
        "  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[2,x].grid(False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQE86ofH3Cfh",
        "colab_type": "text"
      },
      "source": [
        "EXERCISES\n",
        "\n",
        "1. Try editing the convolutions. Change the 32s to either 16 or 64. What impact will this have on accuracy and/or training time.\n",
        "\n",
        "The speed of training would increase as we decrease number of the filter, and the performance would increase as we increase the number of the filter, but the performance generally speaking would flatten out\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nK7OYeC2wUk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "56c8b647-f297-4b69-eec2-c4d07a63000d"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1566 - accuracy: 0.9540\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0545 - accuracy: 0.9836\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0341 - accuracy: 0.9892\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0210 - accuracy: 0.9933\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0155 - accuracy: 0.9951\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0111 - accuracy: 0.9964\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0079 - accuracy: 0.9977\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0078 - accuracy: 0.9972\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0053 - accuracy: 0.9983\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0035 - accuracy: 0.9988\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0584 - accuracy: 0.9857\n",
            "0.9857000112533569\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dz897Hi4LFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "fdb08af3-e28b-4409-9fc2-f30571b0f010"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1715 - accuracy: 0.9494\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0580 - accuracy: 0.9824\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0387 - accuracy: 0.9877\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0267 - accuracy: 0.9920\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0179 - accuracy: 0.9940\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0129 - accuracy: 0.9956\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0095 - accuracy: 0.9969\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0064 - accuracy: 0.9980\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0064 - accuracy: 0.9979\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0049 - accuracy: 0.9983\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0608 - accuracy: 0.9853\n",
            "0.9853000044822693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJp1I7tf4jd0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "c29eac45-2ff2-404e-aa99-aa623ca4e570"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1376 - accuracy: 0.9578\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0484 - accuracy: 0.9849\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0290 - accuracy: 0.9907\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0188 - accuracy: 0.9942\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0125 - accuracy: 0.9960\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0101 - accuracy: 0.9962\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0066 - accuracy: 0.9977\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0061 - accuracy: 0.9980\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0052 - accuracy: 0.9981\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0035 - accuracy: 0.9988\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0498 - accuracy: 0.9895\n",
            "0.9894999861717224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdPlW-lF3MWj",
        "colab_type": "text"
      },
      "source": [
        "2. Remove the final Convolution. What impact will this have on accuracy or training time?\n",
        "Training time is the same with accuracy a bit better\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bKk_Gtq5PGu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "0a1fc295-0d86-4f1f-cacc-f2ba762bc3d0"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1443 - accuracy: 0.9559\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0466 - accuracy: 0.9855\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0317 - accuracy: 0.9898\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0234 - accuracy: 0.9922\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0185 - accuracy: 0.9938\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0133 - accuracy: 0.9959\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0121 - accuracy: 0.9958\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0087 - accuracy: 0.9971\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0083 - accuracy: 0.9969\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0074 - accuracy: 0.9974\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0356 - accuracy: 0.9915\n",
            "0.9915000200271606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_VCuuaV5Poq",
        "colab_type": "text"
      },
      "source": [
        "3. How about adding more Convolutions? What impact do you think this will have? Experiment with it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbFW5S2t6UOV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "fa4002c2-0139-41f9-ec99-4b8848c28e9e"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2617 - accuracy: 0.9177\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0966 - accuracy: 0.9707\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0725 - accuracy: 0.9771\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0579 - accuracy: 0.9822\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0475 - accuracy: 0.9854\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0417 - accuracy: 0.9868\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0357 - accuracy: 0.9885\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0320 - accuracy: 0.9897\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0284 - accuracy: 0.9907\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0240 - accuracy: 0.9922\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0506 - accuracy: 0.9853\n",
            "0.9853000044822693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyJVWrGH6Uv8",
        "colab_type": "text"
      },
      "source": [
        "4. Remove all Convolutions but the first. What impact do you think this will have? Experiment with it. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TGmRKYI6-8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "9a456523-9a35-4963-8096-8a66a90de447"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1469 - accuracy: 0.9560\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0486 - accuracy: 0.9848\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0310 - accuracy: 0.9902\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0206 - accuracy: 0.9934\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0145 - accuracy: 0.9954\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0100 - accuracy: 0.9969\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0082 - accuracy: 0.9971\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0054 - accuracy: 0.9984\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0055 - accuracy: 0.9981\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0044 - accuracy: 0.9986\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0497 - accuracy: 0.9869\n",
            "0.9868999719619751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaGLnwp17fKv",
        "colab_type": "text"
      },
      "source": [
        "5. In the previous lesson you implemented a callback to check on the loss function and to cancel training once it hit a certain amount. See if you can implement that here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT4OZAY869Xn",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}